{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soulvi/Retinopathy/blob/main/ROP_RestNet_3_classes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RboncGx-tmgF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "\n",
        "from torch.cuda import amp\n",
        "from google.colab import drive\n",
        "from torchsummary import summary\n",
        "from PIL import Image, ImageFile\n",
        "from torchvision import transforms\n",
        "from torchvision.io import read_image\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_file_path = '/content/drive/MyDrive/ROP_datasets/annotations.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMM5OCVZt8OW",
        "outputId": "7fc8315c-5420-49f1-feea-38ecc814d983",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TfHFT03qtmgK"
      },
      "outputs": [],
      "source": [
        "class ROP_Dataset(Dataset):\n",
        "    def __init__(self, txt_file, image_dir, transform=None):\n",
        "        self.image_list = pd.read_csv(txt_file, header=None)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_list.iloc[idx, 0])\n",
        "        image = Image.open(img_path)\n",
        "        img_tag = self.image_list.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        sample = {\"image\": image, \"tag\": img_tag}\n",
        "\n",
        "        return image, img_tag"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MEAN = torch.tensor((0.485, 0.456, 0.406))\n",
        "STD  = torch.tensor((0.229, 0.224, 0.225))"
      ],
      "metadata": {
        "id": "MdqYftUjBMbz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=MEAN, std=STD)\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.RandomRotation(15),\n",
        "    # transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "CsxZBoELCAuW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dataset Training\n",
        "dataset_train = ROP_Dataset(txt_file='./annotations/train_3classes.txt', image_dir='./annotations/images', transform=transform)\n",
        "# Create Dataset Testing\n",
        "dataset_test = ROP_Dataset(txt_file='./annotations/test_3classes.txt', image_dir='./annotations/images', transform=transform)\n",
        "# Create Dataset Validation\n",
        "dataset_valid = ROP_Dataset(txt_file='./annotations/valid_3classes.txt', image_dir='./annotations/images', transform=transform)\n",
        "\n",
        "# DataLoader Training\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
        "# DataLoader Testing\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=True)\n",
        "# DataLoader Validation\n",
        "dataloader_valid = DataLoader(dataset_valid, batch_size=32, shuffle=True)\n",
        "\n",
        "print(dataloader_train)\n",
        "print(dataloader_test)\n",
        "print(dataloader_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGKlOA-yBPpw",
        "outputId": "d482f9f1-7b53-4b45-e116-d0f9548a5e07"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7d24eb190d90>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7d24eb192a70>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7d24eb1903a0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using {device} for inference')"
      ],
      "metadata": {
        "id": "Zwf2Ahkrvi93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "561b6eb3-3a98-4753-8640-b996fda3f791"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNetModel, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "        # self.resnet = models.resnet18(weights=None)\n",
        "        num_ftrs = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)"
      ],
      "metadata": {
        "id": "ifPf4NIWF6zd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model, criterion, and optimizer\n",
        "num_classes = 3 # Healthy, Stage 2-3, & Plus\n",
        "model = ResNetModel(num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9-m94OXHD3C",
        "outputId": "5b3352f6-7807-4d76-af43-f76307902154"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 111MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_model(learningRate, num_epochs):\n",
        "  # Define Adam optimizer with the current learning rate\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learningRate)\n",
        "\n",
        "  # Training loop\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      running_loss = 0.0\n",
        "      all_labels = []\n",
        "      all_predictions = []\n",
        "      for inputs, labels in dataloader_train:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          all_labels.extend(labels.cpu().numpy())\n",
        "          all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "      # Calculate average training loss per epoch\n",
        "      epoch_loss = running_loss / len(dataset_train)\n",
        "      precision = precision_score(all_labels, all_predictions, average='weighted')\n",
        "      recall = recall_score(all_labels, all_predictions, average='weighted')\n",
        "      accuracy = accuracy_score(all_labels, all_predictions)\n",
        "      print(f\"Training - Learning Rate: {learningRate} - Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "  # Evaluation loop\n",
        "  model.eval()\n",
        "  all_labels = []\n",
        "  all_predictions = []\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in dataloader_valid:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          all_labels.extend(labels.cpu().numpy())\n",
        "          all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "  precision = precision_score(all_labels, all_predictions, average='weighted')\n",
        "  recall = recall_score(all_labels, all_predictions, average='weighted')\n",
        "  accuracy = accuracy_score(all_labels, all_predictions)\n",
        "  print(f\"\\n\\nValidation - Learning Rate: {learningRate}, Recall: {recall:.4f}, Precision: {precision:.4f}, Accuracy: {accuracy:.4f}\\n\\n\")\n",
        "\n",
        "  torch.save(model.state_dict(), f'resnet_model_lr_{learningRate}.pth')\n",
        "\n",
        "  # Testing loop\n",
        "  # Set model to evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # Lists to store true labels and predicted labels\n",
        "  all_labels = []\n",
        "  all_predictions = []\n",
        "\n",
        "  # Loop through the test dataset\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in dataloader_test:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          # Forward pass\n",
        "          outputs = model(inputs)\n",
        "\n",
        "          # Get predicted labels\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "          # Append true labels and predicted labels\n",
        "          all_labels.extend(labels.cpu().numpy())\n",
        "          all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "  # Calculate precision, recall, and accuracy\n",
        "  precision = precision_score(all_labels, all_predictions, average='weighted')\n",
        "  recall = recall_score(all_labels, all_predictions, average='weighted')\n",
        "  accuracy = accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "  print(f\"Testing - Learning Rate: {learningRate}, Recall: {recall:.4f}, Precision: {precision:.4f}, Accuracy: {accuracy:.4f}\\n\\n\")\n"
      ],
      "metadata": {
        "id": "ILF2ZRJJHRsa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define learning rates\n",
        "learning_rates = [0.001]"
      ],
      "metadata": {
        "id": "Q8qxToS3HQ7D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "\n",
        "for lr in learning_rates:\n",
        "  run_model(lr, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sORvb-mNaukH",
        "outputId": "13a67cbe-4c8d-40f6-8c70-736e256fafda"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Learning Rate: 0.001 - Epoch 1/50, Training Loss: 0.8165, Recall: 0.6773, Precision: 0.6679, Accuracy: 0.6773\n",
            "Training - Learning Rate: 0.001 - Epoch 2/50, Training Loss: 0.3653, Recall: 0.8692, Precision: 0.8713, Accuracy: 0.8692\n",
            "Training - Learning Rate: 0.001 - Epoch 3/50, Training Loss: 0.2541, Recall: 0.9041, Precision: 0.9040, Accuracy: 0.9041\n",
            "Training - Learning Rate: 0.001 - Epoch 4/50, Training Loss: 0.1823, Recall: 0.9360, Precision: 0.9361, Accuracy: 0.9360\n",
            "Training - Learning Rate: 0.001 - Epoch 5/50, Training Loss: 0.2138, Recall: 0.9070, Precision: 0.9089, Accuracy: 0.9070\n",
            "Training - Learning Rate: 0.001 - Epoch 6/50, Training Loss: 0.2260, Recall: 0.9215, Precision: 0.9228, Accuracy: 0.9215\n",
            "Training - Learning Rate: 0.001 - Epoch 7/50, Training Loss: 0.1398, Recall: 0.9622, Precision: 0.9622, Accuracy: 0.9622\n",
            "Training - Learning Rate: 0.001 - Epoch 8/50, Training Loss: 0.1039, Recall: 0.9651, Precision: 0.9654, Accuracy: 0.9651\n",
            "Training - Learning Rate: 0.001 - Epoch 9/50, Training Loss: 0.0816, Recall: 0.9709, Precision: 0.9712, Accuracy: 0.9709\n",
            "Training - Learning Rate: 0.001 - Epoch 10/50, Training Loss: 0.1627, Recall: 0.9564, Precision: 0.9568, Accuracy: 0.9564\n",
            "Training - Learning Rate: 0.001 - Epoch 11/50, Training Loss: 0.1242, Recall: 0.9564, Precision: 0.9573, Accuracy: 0.9564\n",
            "Training - Learning Rate: 0.001 - Epoch 12/50, Training Loss: 0.1157, Recall: 0.9680, Precision: 0.9685, Accuracy: 0.9680\n",
            "Training - Learning Rate: 0.001 - Epoch 13/50, Training Loss: 0.1240, Recall: 0.9593, Precision: 0.9593, Accuracy: 0.9593\n",
            "Training - Learning Rate: 0.001 - Epoch 14/50, Training Loss: 0.0852, Recall: 0.9651, Precision: 0.9655, Accuracy: 0.9651\n",
            "Training - Learning Rate: 0.001 - Epoch 15/50, Training Loss: 0.1231, Recall: 0.9680, Precision: 0.9680, Accuracy: 0.9680\n",
            "Training - Learning Rate: 0.001 - Epoch 16/50, Training Loss: 0.0732, Recall: 0.9738, Precision: 0.9739, Accuracy: 0.9738\n",
            "Training - Learning Rate: 0.001 - Epoch 17/50, Training Loss: 0.0335, Recall: 0.9855, Precision: 0.9855, Accuracy: 0.9855\n",
            "Training - Learning Rate: 0.001 - Epoch 18/50, Training Loss: 0.0691, Recall: 0.9680, Precision: 0.9693, Accuracy: 0.9680\n",
            "Training - Learning Rate: 0.001 - Epoch 19/50, Training Loss: 0.0635, Recall: 0.9767, Precision: 0.9776, Accuracy: 0.9767\n",
            "Training - Learning Rate: 0.001 - Epoch 20/50, Training Loss: 0.0474, Recall: 0.9797, Precision: 0.9797, Accuracy: 0.9797\n",
            "Training - Learning Rate: 0.001 - Epoch 21/50, Training Loss: 0.0879, Recall: 0.9680, Precision: 0.9681, Accuracy: 0.9680\n",
            "Training - Learning Rate: 0.001 - Epoch 22/50, Training Loss: 0.0481, Recall: 0.9767, Precision: 0.9769, Accuracy: 0.9767\n",
            "Training - Learning Rate: 0.001 - Epoch 23/50, Training Loss: 0.0654, Recall: 0.9767, Precision: 0.9771, Accuracy: 0.9767\n",
            "Training - Learning Rate: 0.001 - Epoch 24/50, Training Loss: 0.0736, Recall: 0.9651, Precision: 0.9650, Accuracy: 0.9651\n",
            "Training - Learning Rate: 0.001 - Epoch 25/50, Training Loss: 0.0692, Recall: 0.9738, Precision: 0.9738, Accuracy: 0.9738\n",
            "Training - Learning Rate: 0.001 - Epoch 26/50, Training Loss: 0.0631, Recall: 0.9709, Precision: 0.9716, Accuracy: 0.9709\n",
            "Training - Learning Rate: 0.001 - Epoch 27/50, Training Loss: 0.0519, Recall: 0.9855, Precision: 0.9856, Accuracy: 0.9855\n",
            "Training - Learning Rate: 0.001 - Epoch 28/50, Training Loss: 0.0236, Recall: 0.9971, Precision: 0.9971, Accuracy: 0.9971\n",
            "Training - Learning Rate: 0.001 - Epoch 29/50, Training Loss: 0.0164, Recall: 0.9942, Precision: 0.9942, Accuracy: 0.9942\n",
            "Training - Learning Rate: 0.001 - Epoch 30/50, Training Loss: 0.0161, Recall: 0.9971, Precision: 0.9971, Accuracy: 0.9971\n",
            "Training - Learning Rate: 0.001 - Epoch 31/50, Training Loss: 0.0080, Recall: 0.9971, Precision: 0.9971, Accuracy: 0.9971\n",
            "Training - Learning Rate: 0.001 - Epoch 32/50, Training Loss: 0.0059, Recall: 1.0000, Precision: 1.0000, Accuracy: 1.0000\n",
            "Training - Learning Rate: 0.001 - Epoch 33/50, Training Loss: 0.0259, Recall: 0.9942, Precision: 0.9942, Accuracy: 0.9942\n",
            "Training - Learning Rate: 0.001 - Epoch 34/50, Training Loss: 0.0275, Recall: 0.9826, Precision: 0.9826, Accuracy: 0.9826\n",
            "Training - Learning Rate: 0.001 - Epoch 35/50, Training Loss: 0.0109, Recall: 1.0000, Precision: 1.0000, Accuracy: 1.0000\n",
            "Training - Learning Rate: 0.001 - Epoch 36/50, Training Loss: 0.0043, Recall: 1.0000, Precision: 1.0000, Accuracy: 1.0000\n",
            "Training - Learning Rate: 0.001 - Epoch 37/50, Training Loss: 0.0084, Recall: 0.9971, Precision: 0.9971, Accuracy: 0.9971\n",
            "Training - Learning Rate: 0.001 - Epoch 38/50, Training Loss: 0.0047, Recall: 1.0000, Precision: 1.0000, Accuracy: 1.0000\n",
            "Training - Learning Rate: 0.001 - Epoch 39/50, Training Loss: 0.0439, Recall: 0.9884, Precision: 0.9884, Accuracy: 0.9884\n",
            "Training - Learning Rate: 0.001 - Epoch 40/50, Training Loss: 0.0797, Recall: 0.9738, Precision: 0.9739, Accuracy: 0.9738\n",
            "Training - Learning Rate: 0.001 - Epoch 41/50, Training Loss: 0.1102, Recall: 0.9651, Precision: 0.9650, Accuracy: 0.9651\n",
            "Training - Learning Rate: 0.001 - Epoch 42/50, Training Loss: 0.1000, Recall: 0.9680, Precision: 0.9681, Accuracy: 0.9680\n",
            "Training - Learning Rate: 0.001 - Epoch 43/50, Training Loss: 0.0652, Recall: 0.9738, Precision: 0.9742, Accuracy: 0.9738\n",
            "Training - Learning Rate: 0.001 - Epoch 44/50, Training Loss: 0.0738, Recall: 0.9680, Precision: 0.9683, Accuracy: 0.9680\n",
            "Training - Learning Rate: 0.001 - Epoch 45/50, Training Loss: 0.0540, Recall: 0.9855, Precision: 0.9855, Accuracy: 0.9855\n",
            "Training - Learning Rate: 0.001 - Epoch 46/50, Training Loss: 0.0346, Recall: 0.9942, Precision: 0.9942, Accuracy: 0.9942\n",
            "Training - Learning Rate: 0.001 - Epoch 47/50, Training Loss: 0.0436, Recall: 0.9826, Precision: 0.9832, Accuracy: 0.9826\n",
            "Training - Learning Rate: 0.001 - Epoch 48/50, Training Loss: 0.0259, Recall: 0.9942, Precision: 0.9942, Accuracy: 0.9942\n",
            "Training - Learning Rate: 0.001 - Epoch 49/50, Training Loss: 0.0219, Recall: 0.9942, Precision: 0.9943, Accuracy: 0.9942\n",
            "Training - Learning Rate: 0.001 - Epoch 50/50, Training Loss: 0.0259, Recall: 0.9942, Precision: 0.9942, Accuracy: 0.9942\n",
            "\n",
            "\n",
            "Validation - Learning Rate: 0.001, Recall: 0.9216, Precision: 0.9251, Accuracy: 0.9216\n",
            "\n",
            "\n",
            "Testing - Learning Rate: 0.001, Recall: 0.8750, Precision: 0.8931, Accuracy: 0.8750\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '3cls_best_model.pt')"
      ],
      "metadata": {
        "id": "r3tS2jdyKACM"
      },
      "execution_count": 15,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}